{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Push the model's prediction to Kaggle\n",
    "\n",
    "### Load the model and the data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "/Users/yvesmartin/.pyenv/versions/3.11.6/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/logger_connector/logger_connector.py:67: Starting from v1.9.0, `tensorboardX` has been removed as a dependency of the `lightning.pytorch` package, due to potential conflicts with other packages in the ML ecosystem. For this reason, `logger=True` will use `CSVLogger` as the default logger, unless the `tensorboard` or `tensorboardX` packages are found. Please `pip install lightning[extra]` or one of them to enable TensorBoard support by default\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using local data for: ribonanza\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Wrangling data for ribonanza: 100%|██████████| 49001/49001 [00:03<00:00, 14547.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using local data for: CT_files_pdbee\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Wrangling data for CT_files_pdbee: 100%|██████████| 248/248 [00:00<00:00, 31810.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using local data for: sarah_supermodel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Wrangling data for sarah_supermodel: 100%|██████████| 107/107 [00:00<00:00, 15941.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using local data for: utr\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Wrangling data for utr: 100%|██████████| 1234/1234 [00:00<00:00, 15615.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using local data for: SARS2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Wrangling data for SARS2: 100%|██████████| 38/38 [00:00<00:00, 12206.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using local data for: pri-miRNA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Wrangling data for pri-miRNA: 100%|██████████| 503/503 [00:00<00:00, 15342.41it/s]\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from lightning.pytorch import Trainer\n",
    "import os, sys\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), os.pardir)))\n",
    "from dmsensei.core import DataModule\n",
    "\n",
    "# model = pickle.load(open('model.pkl','rb'))\n",
    "trainer = Trainer()\n",
    "import torch\n",
    "torch.manual_seed(0)\n",
    "np.random.seed(0)\n",
    "\n",
    "dm = DataModule(\n",
    "            name=[\"ribonanza\"],\n",
    "            force_download=False,\n",
    "            batch_size=256,\n",
    "            num_workers=1,\n",
    "            train_split=40,\n",
    "            valid_split=40,\n",
    "            predict_split=1.,\n",
    "            overfit_mode=False,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dms': 27812, 'shape': 38924}\n",
      "[27812, 38924, 40284, 47494, 14670, 4930, 6839, 16248, 48502, 5616, 37044, 26370, 17203, 4398, 7441, 40953, 32119, 33171, 21650, 19924, 43503, 24507, 1253, 23325, 6981, 48085, 38134, 8987, 11119, 10749, 28044, 6376, 24941, 33233, 20810, 45194, 28795, 40005, 11948, 3725]\n",
      "0 0\n",
      "1 2\n"
     ]
    }
   ],
   "source": [
    "indexes = dm.find_one_index_per_data_type('valid')\n",
    "print(indexes)\n",
    "for data, metadata in dm.val_dataloader():\n",
    "    print(metadata['index'])\n",
    "    for data_type in ['dms', 'shape']:\n",
    "        if indexes[data_type] in set(metadata['index']):\n",
    "            idx = metadata['index'].index(indexes[data_type])\n",
    "            batch_idx = data[data_type]['index'][idx].item()\n",
    "            print(idx, batch_idx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rebuild this into a series of lines\n",
    "\n",
    "REFERENCE_METRIC = {\n",
    "    'structure': 'f1', \n",
    "    'dms': 'mae',\n",
    "    'shape': 'mae'\n",
    "}\n",
    "\n",
    "from dmsensei.core.metrics import metric_factory\n",
    "from torch import tensor\n",
    "\n",
    "lines = []\n",
    "for a in dm.predict_dataloader():\n",
    "    break\n",
    "data, metadata = a\n",
    "\n",
    "for idx in range(len(metadata['index'])):\n",
    "    line = {}\n",
    "    for k, v in metadata.items():\n",
    "        line[k] = v[idx]\n",
    "    # for k, v in predictions.items():\n",
    "    #     line['pred_{}'.format(k)] = v[idx]\n",
    "    lines.append(line)\n",
    "for data_type, vals in data.items():\n",
    "    for k,v in zip(vals['index'], vals['values'].tolist()):\n",
    "        name = \"true_{}\".format(data_type) if data_type != 'sequence' else 'sequence'\n",
    "        lines[k.item()][name] = v\n",
    "        lines[k.item()][name.replace('true', 'pred')] = v\n",
    "        \n",
    "for data_type in ['dms','shape']:\n",
    "    for line in lines:\n",
    "        if not ('true_{}'.format(data_type) in line and 'pred_{}'.format(data_type) in line):\n",
    "            continue\n",
    "        line['score_{}'.format(data_type)] = metric_factory[REFERENCE_METRIC[data_type]](pred=tensor(line['pred_{}'.format(data_type)]), true=tensor(line['true_{}'.format(data_type)]), batch=False)\n",
    "    \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data, metadata = a\n",
    "# rebuild this into a series of lines\n",
    "df_lines = pd.DataFrame(metadata)\n",
    "for data_type, arr in data.items():\n",
    "    df_lines = df_lines.merge(\n",
    "        pd.DataFrame(\n",
    "             pd.Series(arr['values'].tolist(), index=arr['index'].tolist()), columns=[data_type]),\n",
    "         how='outer', left_index=True, right_index=True)\n",
    "df_lines    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import json\n",
    "\n",
    "json.dump(lines, open('t.json', 'w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = pd.DataFrame(a[1])\n",
    "metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a[0]['dms']['values'].tolist()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(a[0]['dms']['values'].tolist(), index=a[0]['dms']['index'].tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = trainer.predict(\n",
    "        model,\n",
    "        datamodule=DataModule(\n",
    "            name=[\"ribo-test\"],\n",
    "            data='sequence',\n",
    "            force_download=False,\n",
    "            batch_size=256,\n",
    "            num_workers=1,\n",
    "            train_split=0,\n",
    "            valid_split=0,\n",
    "            predict_split=1.,\n",
    "            overfit_mode=False,\n",
    "        ),\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Format the prediction and save it locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def format_to_ribonanza(prediction):\n",
    "    \n",
    "    # load data (EDIT THIS)\n",
    "    data = json.load(open('/root/DMSensei/scripts/data/input_files/ribo-test/data.json'))\n",
    "    \n",
    "    # reformat into individual sequences\n",
    "    arr = [p for batch in prediction for p in batch]\n",
    "    \n",
    "    # remove padding\n",
    "    arr = [a[:s] for a,s in zip(arr, [len(d['sequence']) for d in data.values()])] \n",
    "    \n",
    "    # stack into dataframe\n",
    "    prediction = np.vstack(arr)\n",
    "    return pd.DataFrame(prediction, columns=[\"reactivity_DMS_MaP\", \"reactivity_2A3_MaP\"]).reset_index().rename(columns={\"index\": \"id\"})\n",
    "\n",
    "format_to_ribonanza(prediction).to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Push the prediction to Kaggle\n",
    "\n",
    "Note: setup your Kaggle authentification first:\n",
    "1. download your Kaggle API keys `kaggle.json` here: https://www.kaggle.com/settings/account\n",
    "2. save it to `~/.kaggle/kaggle.json`:\n",
    "\n",
    "    ```bash\n",
    "    mv ~/Downloads/kaggle.json ~/.kaggle/kaggle.json\n",
    "    ```\n",
    "3. push your results to kaggle using the following line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.system('kaggle competitions submit -c stanford-ribonanza-rna-folding -f submission.csv -m \"test commit\"')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
