{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Push the model's prediction to Kaggle\n",
    "\n",
    "### Load the model and the data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from lightning.pytorch import Trainer\n",
    "import os, sys\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), os.pardir)))\n",
    "from dmsensei.core import DataModule\n",
    "\n",
    "# model = pickle.load(open('model.pkl','rb'))\n",
    "trainer = Trainer()\n",
    "import torch\n",
    "\n",
    "dm = DataModule(\n",
    "            name=[\"ribonanza\"],\n",
    "            force_download=False,\n",
    "            batch_size=256,\n",
    "            num_workers=1,\n",
    "            train_split=40,\n",
    "            valid_split=40,\n",
    "            predict_split=1.,\n",
    "            overfit_mode=False,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexes = dm.find_one_index_per_data_type('valid')\n",
    "print(indexes)\n",
    "for data, metadata in dm.val_dataloader():\n",
    "    print(metadata['index'])\n",
    "    for data_type in ['dms', 'shape']:\n",
    "        if indexes[data_type] in set(metadata['index']):\n",
    "            idx = metadata['index'].index(indexes[data_type])\n",
    "            batch_idx = data[data_type]['index'][idx].item()\n",
    "            print(idx, batch_idx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rebuild this into a series of lines\n",
    "\n",
    "REFERENCE_METRIC = {\n",
    "    'structure': 'f1', \n",
    "    'dms': 'mae',\n",
    "    'shape': 'mae'\n",
    "}\n",
    "\n",
    "from dmsensei.core.metrics import metric_factory\n",
    "from torch import tensor\n",
    "\n",
    "lines = []\n",
    "for a in dm.predict_dataloader():\n",
    "    break\n",
    "data, metadata = a\n",
    "\n",
    "for idx in range(len(metadata['index'])):\n",
    "    line = {}\n",
    "    for k, v in metadata.items():\n",
    "        line[k] = v[idx]\n",
    "    # for k, v in predictions.items():\n",
    "    #     line['pred_{}'.format(k)] = v[idx]\n",
    "    lines.append(line)\n",
    "for data_type, vals in data.items():\n",
    "    for k,v in zip(vals['index'], vals['values'].tolist()):\n",
    "        name = \"true_{}\".format(data_type) if data_type != 'sequence' else 'sequence'\n",
    "        lines[k.item()][name] = v\n",
    "        lines[k.item()][name.replace('true', 'pred')] = v\n",
    "        \n",
    "for data_type in ['dms','shape']:\n",
    "    for line in lines:\n",
    "        if not ('true_{}'.format(data_type) in line and 'pred_{}'.format(data_type) in line):\n",
    "            continue\n",
    "        line['score_{}'.format(data_type)] = metric_factory[REFERENCE_METRIC[data_type]](pred=tensor(line['pred_{}'.format(data_type)]), true=tensor(line['true_{}'.format(data_type)]), batch=False)\n",
    "    \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data, metadata = a\n",
    "# rebuild this into a series of lines\n",
    "df_lines = pd.DataFrame(metadata)\n",
    "for data_type, arr in data.items():\n",
    "    df_lines = df_lines.merge(\n",
    "        pd.DataFrame(\n",
    "             pd.Series(arr['values'].tolist(), index=arr['index'].tolist()), columns=[data_type]),\n",
    "         how='outer', left_index=True, right_index=True)\n",
    "df_lines    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import json\n",
    "\n",
    "json.dump(lines, open('t.json', 'w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = pd.DataFrame(a[1])\n",
    "metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a[0]['dms']['values'].tolist()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(a[0]['dms']['values'].tolist(), index=a[0]['dms']['index'].tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = trainer.predict(\n",
    "        model,\n",
    "        datamodule=DataModule(\n",
    "            name=[\"ribo-test\"],\n",
    "            data='sequence',\n",
    "            force_download=False,\n",
    "            batch_size=256,\n",
    "            num_workers=1,\n",
    "            train_split=0,\n",
    "            valid_split=0,\n",
    "            predict_split=1.,\n",
    "            overfit_mode=False,\n",
    "        ),\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Format the prediction and save it locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def format_to_ribonanza(prediction):\n",
    "    \n",
    "    # load data (EDIT THIS)\n",
    "    data = json.load(open('/root/DMSensei/scripts/data/input_files/ribo-test/data.json'))\n",
    "    \n",
    "    # reformat into individual sequences\n",
    "    arr = [p for batch in prediction for p in batch]\n",
    "    \n",
    "    # remove padding\n",
    "    arr = [a[:s] for a,s in zip(arr, [len(d['sequence']) for d in data.values()])] \n",
    "    \n",
    "    # stack into dataframe\n",
    "    prediction = np.vstack(arr)\n",
    "    return pd.DataFrame(prediction, columns=[\"reactivity_DMS_MaP\", \"reactivity_2A3_MaP\"]).reset_index().rename(columns={\"index\": \"id\"})\n",
    "\n",
    "format_to_ribonanza(prediction).to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Push the prediction to Kaggle\n",
    "\n",
    "Note: setup your Kaggle authentification first:\n",
    "1. download your Kaggle API keys `kaggle.json` here: https://www.kaggle.com/settings/account\n",
    "2. save it to `~/.kaggle/kaggle.json`:\n",
    "\n",
    "    ```bash\n",
    "    mv ~/Downloads/kaggle.json ~/.kaggle/kaggle.json\n",
    "    ```\n",
    "3. push your results to kaggle using the following line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.system('kaggle competitions submit -c stanford-ribonanza-rna-folding -f submission.csv -m \"test commit\"')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
