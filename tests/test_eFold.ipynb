{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import efold.core as core\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from rouskinhf import get_dataset\n",
    "import torch\n",
    "\n",
    "import os\n",
    "\n",
    "os.environ['HUGGINGFACE_TOKEN'] = 'your key here'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth = pd.DataFrame()\n",
    "\n",
    "for test_set in [\"PDB\", \"archiveII\", \"viral_fragments\", \"lncRNA_nonFiltered\"]:\n",
    "    data = get_dataset(test_set, force_download=True)\n",
    "    data = pd.DataFrame(data).T[['sequence', 'structure']]\n",
    "    data['dataset'] = test_set\n",
    "\n",
    "    ground_truth = pd.concat([ground_truth, data])\n",
    "    del data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ratio_nonCanonical(sequence, structure):\n",
    "\n",
    "    if len(structure) == 0: return 0\n",
    "\n",
    "    canonical_pairs = set(['AU', 'UA', 'GC', 'CG', 'GU', 'UG'])\n",
    "\n",
    "    non_canonical = [ ''.join([sequence[i] for i in pair]) not in canonical_pairs for pair in structure]\n",
    "\n",
    "    return sum(non_canonical)/len(structure)\n",
    "\n",
    "\n",
    "\n",
    "def ratio_sharpLoops(structure, min_dist=3):\n",
    "\n",
    "    if len(structure) == 0: return 0\n",
    "\n",
    "    sharp_loops = [ np.abs(pair[1]-pair[0])<=min_dist for pair in structure ]\n",
    "\n",
    "    return sum(sharp_loops).item()/len(structure)\n",
    "\n",
    "sequence = 'AUGAC'\n",
    "structure = [[0,2], [0,1]]\n",
    "ratio_nonCanonical(sequence, structure), ratio_sharpLoops(structure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ListofPairs2pairMatrix(pairs, length):\n",
    "    matrix = torch.zeros((length, length))\n",
    "\n",
    "    if len(pairs) == 0: return matrix\n",
    "    matrix[pairs[:,0], pairs[:,1]] = 1\n",
    "    matrix[pairs[:,1], pairs[:,0]] = 1\n",
    "\n",
    "    return matrix.int()\n",
    "\n",
    "\n",
    "def compute_f1(pred_matrix, target_matrix, threshold=0.5):\n",
    "    \"\"\"\n",
    "    Compute the F1 score of the predictions.\n",
    "\n",
    "    :param pred_matrix: Predicted pairing matrix probability  (L,L)\n",
    "    :param target_matrix: True binary pairing matrix (L,L)\n",
    "    :return: precision, recall F1 score for this RNA structure\n",
    "    \"\"\"\n",
    "\n",
    "    pred_matrix = (pred_matrix > threshold).float()\n",
    "\n",
    "\n",
    "    TP = torch.sum(pred_matrix*target_matrix)\n",
    "    PP = torch.sum(pred_matrix)\n",
    "    P = torch.sum(target_matrix)\n",
    "    sum_pair = PP + P\n",
    "\n",
    "    if sum_pair == 0:\n",
    "        return [1.0, 1.0, 1.0]\n",
    "    else:\n",
    "        return [\n",
    "                (TP / PP).item(),\n",
    "                (TP / P).item(),\n",
    "                (2 * TP / sum_pair).item()\n",
    "                ]\n",
    "\n",
    "def compute_confusion_matrix(label, pred):\n",
    "    true_negatives = (1 - label) * (1 - pred)\n",
    "    true_positives = label * pred\n",
    "    false_positives = (1 - label) * pred\n",
    "    false_negatives = label * (1 - pred)\n",
    "    confusion_matrix = true_positives + false_positives * 2 + false_negatives * 3\n",
    "    assert ((true_negatives == 1) == (confusion_matrix == 0)).all(), \"True negatives are not correctly computed\"\n",
    "    return confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth['non_canonical'] = ground_truth.apply(lambda x: ratio_nonCanonical(x['sequence'], x['structure']), axis=1)\n",
    "ground_truth['sharp_loops'] = ground_truth.apply(lambda x: ratio_sharpLoops(x['structure']), axis=1)\n",
    "ground_truth[ground_truth['sharp_loops'] >0]\n",
    "ground_truth['pairing_matrix'] = ground_truth.apply(lambda x: ListofPairs2pairMatrix(np.array(x['structure']), len(x['sequence'])), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from tqdm import tqdm\n",
    "from efold import inference\n",
    "\n",
    "eFold_processed = pd.DataFrame()\n",
    "\n",
    "thresholds = [0.5]\n",
    "\n",
    "for threshold in thresholds:\n",
    "    print(f\"Threshold: {threshold}\")\n",
    "\n",
    "    Precisions = []\n",
    "    Recalls = []\n",
    "    F1s = []\n",
    "    predictions = []\n",
    "    dTs = []\n",
    "\n",
    "    for idx, row in tqdm(ground_truth.iterrows(), total=len(ground_truth)):\n",
    "        true_structure = torch.tensor(row['structure'])\n",
    "        sequence = row['sequence']\n",
    "\n",
    "        t0 = time.time()\n",
    "        prediction = torch.tensor(inference(sequence, fmt='bp')[sequence])-1\n",
    "        dT = time.time() - t0\n",
    "\n",
    "        precision, recall, f1 = compute_f1(ListofPairs2pairMatrix(prediction, len(sequence)), \n",
    "                                           ListofPairs2pairMatrix(true_structure, len(sequence)))\n",
    "\n",
    "        Precisions.append(precision)\n",
    "        Recalls.append(recall)\n",
    "        F1s.append(f1)\n",
    "        predictions.append(prediction)\n",
    "        dTs.append(dT)\n",
    "\n",
    "    eFold_processed = pd.concat([eFold_processed, pd.DataFrame({'reference': ground_truth.index, 'sequence': ground_truth['sequence'],\n",
    "                                                                'threshold': threshold,\n",
    "                                                                'precision': Precisions, 'recall': Recalls, 'f1': F1s, 'dT': dTs,\n",
    "                                                                'structure': predictions})], axis=0)\n",
    "# Add dataset name\n",
    "eFold_processed = eFold_processed.merge(ground_truth.reset_index().rename(columns={'index':'reference'})[['reference', 'sequence', 'dataset']], on=['reference', 'sequence'])\n",
    "# eFold_processed['basePairs'] = eFold_processed['structure'].apply(lambda x: torch.unique(torch.sort(torch.stack(torch.where(x>0)).T, dim=1)[0], dim=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eFold_processed['non_canonical'] = eFold_processed.apply(lambda x: ratio_nonCanonical(x['sequence'], x['structure']), axis=1)\n",
    "eFold_processed['sharp_loops'] = eFold_processed.apply(lambda x: ratio_sharpLoops(x['structure']), axis=1)\n",
    "eFold_processed['pairing_matrix'] = eFold_processed.apply(lambda x: ListofPairs2pairMatrix(x['structure'], len(x['sequence'])), axis=1)\n",
    "eFold_processed['multiPairs'] = eFold_processed['pairing_matrix'].apply(lambda x: (x.sum(axis=0) >1).sum().item()/len(x) )\n",
    "eFold_processed['length'] = eFold_processed['sequence'].apply(len)\n",
    "\n",
    "eFold_processed.groupby('threshold')[['non_canonical', 'sharp_loops', 'multiPairs']].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group the data by model and dataset and calculate the mean for each group\n",
    "grouped = eFold_processed.groupby(['threshold', 'dataset']).mean(numeric_only=True).reset_index()\n",
    "\n",
    "# Pivot the table to create a multi-level column structure\n",
    "pivot_df = pd.pivot_table(grouped, index='threshold', columns='dataset', values=['precision', 'recall', 'f1'])\n",
    "\n",
    "# Swap the level of the columns to have dataset as the top level and the metrics as the second level\n",
    "pivot_df = pivot_df.swaplevel(i=0, j=1, axis=1).sort_index(axis=1)\n",
    "\n",
    "# Define the new order for the models and reorder the rows\n",
    "# new_order = ['SimpleThreshold', 'HungarianAlgorithm', 'UFold_processing', 'OptimalProcessing']\n",
    "# pivot_df = pivot_df.reindex(new_order)\n",
    "\n",
    "pivot_df = pivot_df.reindex(columns=pivot_df.columns.reindex(['precision', 'recall', 'f1'], level=1)[0])[['PDB', 'archiveII_blast', 'viral_fragments', 'lncRNA_nonFiltered']]\n",
    "\n",
    "pivot_df = pivot_df.style\\\n",
    "            .format(precision=3)\\\n",
    "            .highlight_max(axis=0, props=\"font-weight:bold;font-color:black;\")\\\n",
    "            .background_gradient(axis=1, vmin=-0.1, vmax=1, cmap=\"viridis\", text_color_threshold=0)\\\n",
    "            .set_properties(**{'text-align': 'center'})\\\n",
    "            .set_table_styles(\n",
    "                        [{\"selector\": \"th\", \"props\": [('text-align', 'center')]},\n",
    "                        ])\n",
    "pivot_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
