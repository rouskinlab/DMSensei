{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "import sys, os\n",
    "sys.path.append(os.path.abspath(os.path.join('..')))\n",
    "\n",
    "from dmsensei import DataModule, create_model, Dataset\n",
    "from dmsensei.config import device\n",
    "from dmsensei.core.callbacks import WandbFitLogger, KaggleLogger\n",
    "from lightning.pytorch.callbacks import LearningRateMonitor\n",
    "from lightning.pytorch import Trainer\n",
    "from dmsensei.config import device\n",
    "import sys\n",
    "import os\n",
    "from lightning.pytorch.loggers import WandbLogger\n",
    "import torch, wandb\n",
    "import numpy as np\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yack: Downloading dataset from HuggingFace Hub...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3dc09c9990fd4a34a33e759a435db84d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 1 files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yack: Download complete. File saved at data/yack/data.json\n",
      "Loading dataset from HF\n",
      "Done!                            \n",
      "structure 133456\n",
      "dms 133456\n",
      "shape 133456\n"
     ]
    }
   ],
   "source": [
    "ds = Dataset.from_local_or_download(\n",
    "    'yack'\n",
    ")\n",
    "print('structure', len(ds.structure.true))\n",
    "print('dms', len(ds.dms.true))\n",
    "print('shape', len(ds.shape.true))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset from disk\n",
      "Done!                            \n"
     ]
    }
   ],
   "source": [
    "dm = DataModule(\n",
    "    name=['archiveII', 'RNAStralign','bpRNA'],\n",
    "    batch_size=32,\n",
    "    train_split=None,\n",
    ")\n",
    "dm.setup('fit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1000., -1000., -1000.,  ..., -1000., -1000., -1000.],\n",
      "        [-1000., -1000., -1000.,  ..., -1000., -1000., -1000.],\n",
      "        [-1000., -1000., -1000.,  ..., -1000., -1000., -1000.],\n",
      "        ...,\n",
      "        [-1000., -1000., -1000.,  ..., -1000., -1000., -1000.],\n",
      "        [-1000., -1000., -1000.,  ..., -1000., -1000., -1000.],\n",
      "        [-1000., -1000., -1000.,  ..., -1000., -1000., -1000.]],\n",
      "       device='mps:0')\n"
     ]
    }
   ],
   "source": [
    "for batch in dm.train_dataloader():\n",
    "    print(batch.get('dms'))\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "name = 'yack'\n",
    "data = json.load(open(f'./data/{name}/data.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 2796/4171 [01:14<00:35, 38.89it/s]"
     ]
    }
   ],
   "source": [
    "from dmsensei.core.util import _pad, base_pairs_to_pairing_matrix\n",
    "import tqdm \n",
    "\n",
    "def compare_data(dt, data_line, from_ds, ref):\n",
    "    from_ds = from_ds.cpu().reshape(-1).tolist()\n",
    "    \n",
    "    if not dt in data_line:\n",
    "        assert from_ds is None or set(from_ds) == set([-1000.]), f'{dt} is None in the json and not not in the datamodule for {ref}: {from_ds}'\n",
    "        return\n",
    "    L = len(data_line['sequence'])\n",
    "    data_line = data_line[dt]\n",
    "    \n",
    "    if dt == 'structure':\n",
    "        data_line = base_pairs_to_pairing_matrix(data_line, L, padding=len(from_ds))\n",
    "\n",
    "    else:\n",
    "        from_ds = np.array(from_ds)[:L].round(4)\n",
    "        data_line = np.array(data_line).round(4)\n",
    "    \n",
    "    if not (data_line == from_ds).all():\n",
    "        assert 0, f'{dt} keys do not match for {ref}: \\ndata_line:\\t{data_line} \\nfrom_ds:\\t{from_ds}'\n",
    "    return\n",
    "\n",
    "def sanity_check(data:dict, dm:DataModule):\n",
    "    for batch in tqdm.tqdm(dm.train_dataloader(), total=len(dm.train_dataloader())):\n",
    "        for ref, dms, shape, structure in zip(batch.get('reference'), batch.get('dms'), batch.get('shape'), batch.get('structure')):\n",
    "            for dt, from_ds in zip(['dms', 'shape', 'structure'], [dms, shape, structure]):\n",
    "                if dt == 'structure':\n",
    "                    continue\n",
    "                compare_data(dt, data[ref], from_ds, ref)\n",
    "\n",
    "sanity_check(data, dm)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
